{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T13:11:02.310789Z",
     "start_time": "2019-01-01T13:09:42.363237Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\persp\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\persp\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   9 | elapsed:   54.5s remaining:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_num,train_test_radio\n",
      "(5000, 6)\n",
      "best_score0.92975495915986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[5000, 6, {'n_neighbors': 4, 'weights': 'distance'}, 0.9356643356643357]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "mnist = fetch_mldata('MNIST original',data_home=\"C:/Users/persp/workspace/GitHub/Hands-on-Machine-Learning/datasets/\")\n",
    "mnist\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "shuffle_index = np.random.permutation(len(X))\n",
    "shuffle_index\n",
    "X, y= X[shuffle_index], y[shuffle_index]\n",
    "result =[]\n",
    "# for sample_num in [1000,2000,4000,6000,8000,10000]:\n",
    "for sample_num in [5000]:\n",
    "#     for train_test_radio in [4,5,6]:\n",
    "    for train_test_radio in [6]:\n",
    "\n",
    "        x_sample,y_sample= X[:sample_num],y[:sample_num]\n",
    "#         train_test_radio =5/1\n",
    "        sample_train_num = int(sample_num*train_test_radio/(train_test_radio+1))\n",
    "        x_sample_train,y_sample_train =x_sample[:sample_train_num],y_sample[:sample_train_num]\n",
    "        x_sample_test,y_sample_test = x_sample[sample_train_num:],y_sample[sample_train_num:]\n",
    "        # y_sample[0]==y_sample_train[0]\n",
    "        # y_sample[-1]==y_sample_test[-1]\n",
    "\n",
    "\n",
    "        knn_clf = KNeighborsClassifier()\n",
    "        param_grid = [{'weights': [ \"distance\"], 'n_neighbors': [3, 4, 5]}]\n",
    "        # 网格搜索\n",
    "        grid_search = GridSearchCV(knn_clf, param_grid, cv=3, verbose=3, n_jobs=-1)\n",
    "        grid_search.fit(x_sample_train, y_sample_train)\n",
    "        print('sample_num,train_test_radio')\n",
    "        print((sample_num,train_test_radio))\n",
    "        print(('best_score' + str(grid_search.best_score_)))\n",
    "\n",
    "        y_sample_pred = grid_search.predict(x_sample_test)\n",
    "        test_score =accuracy_score(y_sample_test, y_sample_pred)\n",
    "        result.append([sample_num,train_test_radio,grid_search.best_params_,test_score])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-25T22:06:05.852326Z",
     "start_time": "2018-12-25T22:06:05.844331Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T13:11:04.899127Z",
     "start_time": "2019-01-01T13:11:02.315786Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\persp\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\persp\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([22391, 38477, 43348, ..., 40739, 60559, 42356])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=4, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8881118881118881"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shift\n",
      "shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(857, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=4, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "mnist = fetch_mldata('MNIST original',data_home=\"C:/Users/persp/workspace/GitHub/Hands-on-Machine-Learning/datasets/\")\n",
    "mnist\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "shuffle_index = np.random.permutation(len(X))\n",
    "shuffle_index\n",
    "X, y= X[shuffle_index], y[shuffle_index]\n",
    "\n",
    "\n",
    "sample_num =1000\n",
    "train_test_radio =6\n",
    "x_sample,y_sample= X[:sample_num],y[:sample_num]\n",
    "sample_train_num = int(sample_num*train_test_radio/(train_test_radio+1))\n",
    "x_sample_train,y_sample_train =x_sample[:sample_train_num],y_sample[:sample_train_num]\n",
    "x_sample_test,y_sample_test = x_sample[sample_train_num:],y_sample[sample_train_num:]\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1, weights='distance', n_neighbors=4)\n",
    "knn_clf.fit(x_sample_train, y_sample_train)\n",
    "y_sample_pred = knn_clf.predict(x_sample_test)\n",
    "accuracy_score(y_sample_test, y_sample_pred)\n",
    "## Data Augmentation\n",
    "\n",
    "##\n",
    "print('shift')\n",
    "from scipy.ndimage.interpolation import shift\n",
    "def shift_image(image, dx, dy):\n",
    "    image = image.reshape((28, 28))\n",
    "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
    "    return shifted_image.reshape([-1])\n",
    "print('shape')\n",
    "x_sample_train.shape\n",
    "X_train_augmented = [image for image in x_sample_train]\n",
    "y_train_augmented = [label for label in y_sample_train]\n",
    "\n",
    "for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "    for image, label in zip(x_sample_train, y_sample_train):\n",
    "        X_train_augmented.append(shift_image(image, dx, dy))\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "X_train_augmented = np.array(X_train_augmented)\n",
    "y_train_augmented = np.array(y_train_augmented)\n",
    "\n",
    "\n",
    "shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "y_train_augmented = y_train_augmented[shuffle_idx]\n",
    "knn_clf = KNeighborsClassifier(**grid_search.best_params_)\n",
    "knn_clf.fit(X_train_augmented, y_train_augmented)\n",
    "y_sample_pred = knn_clf.predict(x_sample_test)\n",
    "accuracy_score(y_sample_test, y_sample_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T13:11:04.921111Z",
     "start_time": "2019-01-01T13:11:04.902124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4285"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-01T13:13:38.721796Z",
     "start_time": "2019-01-01T13:13:38.702808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6]\n",
      "\n",
      "[[1 4]\n",
      " [2 5]\n",
      " [3 6]]\n",
      "\n",
      "[[1 4 1]\n",
      " [2 5 2]\n",
      " [3 6 3]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "c = np.c_[a,b]\n",
    "\n",
    "print((np.r_[a,b]))\n",
    "print('')\n",
    "print(c)\n",
    "print('')\n",
    "print((np.c_[c,a]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
