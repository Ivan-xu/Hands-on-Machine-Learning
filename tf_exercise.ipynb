{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T05:00:43.842245Z",
     "start_time": "2019-04-14T05:00:43.432513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Conv2D_46:0' shape=(1, 3, 3, 2) dtype=float32>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[[[-3.3139977 , -6.8762264 ],\n",
       "         [ 2.8617148 ,  1.3386506 ],\n",
       "         [ 1.890465  ,  4.4339914 ]],\n",
       "\n",
       "        [[-0.35802194, -0.58589315],\n",
       "         [ 1.9047356 ,  0.37049937],\n",
       "         [-1.2530187 ,  1.4562831 ]],\n",
       "\n",
       "        [[-3.5003998 ,  2.3608975 ],\n",
       "         [ 0.87821424, -1.2328389 ],\n",
       "         [ 2.2777224 ,  0.03464177]]]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#20190413 \n",
    "# 更改为每行输出\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "import tensorflow as tf\n",
    "input = tf.Variable(tf.random_normal([1,3,3,5]))\n",
    "filter = tf.Variable(tf.random_normal([1,1,5,2]))\n",
    "\n",
    "op = tf.nn.conv2d(input, filter, strides=[1, 1, 1, 1], padding='VALID')\n",
    "op\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    sess.run(op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T07:36:22.666475Z",
     "start_time": "2019-04-14T07:36:22.028363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------case 2---------\n",
      "[[[[5.]\n",
      "   [5.]\n",
      "   [5.]]\n",
      "\n",
      "  [[5.]\n",
      "   [5.]\n",
      "   [5.]]\n",
      "\n",
      "  [[5.]\n",
      "   [5.]\n",
      "   [5.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 3---------\n",
      "[[[[45.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 4---------\n",
      "[[[[45.]\n",
      "   [45.]\n",
      "   [45.]]\n",
      "\n",
      "  [[45.]\n",
      "   [45.]\n",
      "   [45.]]\n",
      "\n",
      "  [[45.]\n",
      "   [45.]\n",
      "   [45.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 5---------\n",
      "[[[[20.]\n",
      "   [30.]\n",
      "   [30.]\n",
      "   [30.]\n",
      "   [20.]]\n",
      "\n",
      "  [[30.]\n",
      "   [45.]\n",
      "   [45.]\n",
      "   [45.]\n",
      "   [30.]]\n",
      "\n",
      "  [[30.]\n",
      "   [45.]\n",
      "   [45.]\n",
      "   [45.]\n",
      "   [30.]]\n",
      "\n",
      "  [[30.]\n",
      "   [45.]\n",
      "   [45.]\n",
      "   [45.]\n",
      "   [30.]]\n",
      "\n",
      "  [[20.]\n",
      "   [30.]\n",
      "   [30.]\n",
      "   [30.]\n",
      "   [20.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 6---------\n",
      "[[[[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]\n",
      "\n",
      "  [[30. 30. 30. 30. 30. 30. 30.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]]\n",
      "\n",
      "  [[30. 30. 30. 30. 30. 30. 30.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]]\n",
      "\n",
      "  [[30. 30. 30. 30. 30. 30. 30.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]]\n",
      "\n",
      "  [[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 7---------\n",
      "[[[[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]\n",
      "\n",
      "  [[30. 30. 30. 30. 30. 30. 30.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]]\n",
      "\n",
      "  [[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]]]\n",
      "---------------------\n",
      "\n",
      "\n",
      "----------case 8---------\n",
      "[[[[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]\n",
      "\n",
      "  [[30. 30. 30. 30. 30. 30. 30.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]]\n",
      "\n",
      "  [[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]]\n",
      "\n",
      "\n",
      " [[[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]\n",
      "\n",
      "  [[30. 30. 30. 30. 30. 30. 30.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]]\n",
      "\n",
      "  [[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]]\n",
      "\n",
      "\n",
      " [[[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]\n",
      "\n",
      "  [[30. 30. 30. 30. 30. 30. 30.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]]\n",
      "\n",
      "  [[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]]\n",
      "\n",
      "\n",
      " [[[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]\n",
      "\n",
      "  [[30. 30. 30. 30. 30. 30. 30.]\n",
      "   [45. 45. 45. 45. 45. 45. 45.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]]\n",
      "\n",
      "  [[20. 20. 20. 20. 20. 20. 20.]\n",
      "   [30. 30. 30. 30. 30. 30. 30.]\n",
      "   [20. 20. 20. 20. 20. 20. 20.]]]]\n",
      "---------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)\n",
    "# 除去name参数用以指定该操作的name，与方法有关的一共五个参数：\n",
    "#\n",
    "# 第一个参数input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，注意这是一个4维的Tensor，要求类型为float32和float64其中之一\n",
    "#\n",
    "# 第二个参数filter：相当于CNN中的卷积核，它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape，具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同，有一个地方需要注意，第三维in_channels，就是参数input的第四维\n",
    "#\n",
    "# 第三个参数strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4\n",
    "#\n",
    "# 第四个参数padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，这个值决定了不同的卷积方式（后面会介绍）\n",
    "#\n",
    "# 第五个参数：use_cudnn_on_gpu:bool类型，是否使用cudnn加速，默认为true\n",
    "#\n",
    "# 结果返回一个Tensor，这个输出，就是我们常说的feature map\n",
    "\n",
    "oplist=[]\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 3, 3, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([1 ,1 , 5 ,1]))\n",
    "\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='VALID')\n",
    "oplist.append([op2, \"case 2\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 3, 3, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,1]))\n",
    "\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='VALID')\n",
    "oplist.append([op2, \"case 3\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,1]))\n",
    "\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='VALID')\n",
    "oplist.append([op2, \"case 4\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,1]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='SAME')\n",
    "oplist.append([op2, \"case 5\"])\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,7]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,1,1,1], use_cudnn_on_gpu=False, padding='SAME')\n",
    "oplist.append([op2, \"case 6\"])\n",
    "\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([1, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,7]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,2,2,1], use_cudnn_on_gpu=False, padding='SAME')\n",
    "oplist.append([op2, \"case 7\"])\n",
    "\n",
    "\n",
    "# [batch, in_height, in_width, in_channels]\n",
    "input_arg  = tf.Variable(tf.ones([4, 5, 5, 5]))\n",
    "# [filter_height, filter_width, in_channels, out_channels]\n",
    "filter_arg = tf.Variable(tf.ones([3 ,3 , 5 ,7]))\n",
    "op2 = tf.nn.conv2d(input_arg, filter_arg, strides=[1,2,2,1], use_cudnn_on_gpu=False, padding='SAME')\n",
    "oplist.append([op2, \"case 8\"])\n",
    "\n",
    "with tf.Session() as a_sess:\n",
    "    a_sess.run(tf.global_variables_initializer())\n",
    "    for aop in oplist:\n",
    "        print(\"----------{}---------\".format(aop[1]))\n",
    "        print(a_sess.run(aop[0]))\n",
    "        print('---------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T04:28:33.587574Z",
     "start_time": "2019-03-23T04:28:33.528683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "# 更改为每行输出\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" \n",
    "\n",
    "import numpy as np\n",
    "def logprint(key,msg=None):\n",
    "    type_key = type(key)\n",
    "    if type_key ==str:\n",
    "        shape = len(key)\n",
    "    elif type_key ==np.ndarray:\n",
    "        shape =key.shape\n",
    "    else:\n",
    "        shape =None\n",
    "    if shape !=None:\n",
    "        print((\"logprint\\tmsg:\"+str(msg)+\"\\ttype:\"+str(type(key))+\"\\tshape:\"+str(shape)))\n",
    "    else:\n",
    "        print((\"logprint\\tmsg:\"+str(msg)+\"\\ttype:\"+str(type(key))))\n",
    "    print(key)\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:00:06.607886Z",
     "start_time": "2019-03-07T14:00:06.588900Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state = tf.Variable(0,name = 'counter')\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state,one)\n",
    "update = tf.assign(state,new_value)\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:08:09.184529Z",
     "start_time": "2019-03-07T14:08:09.150550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "1\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "#     print(sess.run(new_value))\n",
    "    print((sess.run(state)))\n",
    "    for _ in range(3):\n",
    "        sess.run(update)\n",
    "        print(sess.run(new_value))\n",
    "        print((sess.run(state)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T07:52:42.501662Z",
     "start_time": "2019-03-16T07:52:42.470722Z"
    }
   },
   "source": [
    "TensorFlow操作（也简称为**ops**）可以接受任意数量的输入和产生任意数量的输出。例如，\n",
    "* 加法和乘法运算每个都需要两个输入并产生一个输出。\n",
    "* 常量和变量不需要输入（它们被称为**源操作**）。\n",
    "* 输入和输出是多维数组，称为**张量**（因此称为“张量流”）。\n",
    "\n",
    "就像NumPy数组一样，张量具有类型和形状。实际上，**在Python API中，张量只是由NumPy ndarrays表示**。它们通常包含浮点数，但你也可以使用它们来携带字符串（任意字节数组）。\n",
    "\n",
    "在到目前为止的示例中，张量只包含一个标量值，但你当然可以对任何形状的数组执行计算。例如，以下代码操作2D数组以对California住房数据集执行**线性回归**（在第2章中介绍）。\n",
    "\n",
    "* 它首先获取数据集;\n",
    "* 然后它为所有训练实例添加了一个**额外的偏置输入特征**($x_0 = 1$)（它使用NumPy这样做，因此它立即运行）;\n",
    "* 最后它创建两个TensorFlow常量节点 X 和 y 来保存这些数据和目标，它使用TensorFlow提供的一些矩阵运算来定义**theta**。\n",
    "\n",
    "这些矩阵函数—**transpose()，matmul()和matrix_inverse()** —是一目了然的，但通常它们不会立即执行任何计算;相反，\n",
    "* 他们在图表中创建节点，在运行图表时执行它们。你可以认识到 $θ$ 的定义对应于法线方程($θ= X^T·X^{-1}·X^T·y $；见第4章)。\n",
    "* 最后，代码创建一个会话并使用它来评估**theta**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T08:04:21.926803Z",
     "start_time": "2019-03-16T08:04:21.873903Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset_graph()\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "x = tf.constant(housing_data_plus_bias,dtype= tf.float32,name= 'X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\") \n",
    "XT = tf.transpose(x)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(x,x,transpose_a=True)),x,transpose_b=True),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T08:03:44.422052Z",
     "start_time": "2019-03-16T08:03:44.367156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.7185181e+01],\n",
       "       [ 4.3633747e-01],\n",
       "       [ 9.3952334e-03],\n",
       "       [-1.0711310e-01],\n",
       "       [ 6.4479220e-01],\n",
       "       [-4.0338000e-06],\n",
       "       [-3.7813708e-03],\n",
       "       [-4.2348403e-01],\n",
       "       [-4.3721911e-01]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "theta_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-16T10:08:39.863228Z",
     "start_time": "2019-03-16T10:08:39.161565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 2.7544262\n",
      "Epoch 100 MSE = 0.52731586\n",
      "Epoch 200 MSE = 0.52441466\n",
      "Epoch 300 MSE = 0.52432835\n",
      "Epoch 400 MSE = 0.5243219\n",
      "Epoch 500 MSE = 0.524321\n",
      "Epoch 600 MSE = 0.52432066\n",
      "Epoch 700 MSE = 0.524321\n",
      "Epoch 800 MSE = 0.52432126\n",
      "Epoch 900 MSE = 0.524321\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\" \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "# reset_graph()\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "##########################################################\n",
    "##手动计算梯度\n",
    "# gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "\n",
    "\n",
    "# training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "##########################################################\n",
    "##########################################################\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate =learning_rate,momentum =0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "##########################################################\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:# 每100次迭代打印出当前的均方误差（mse）\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-28T14:29:47.959790Z",
     "start_time": "2019-03-28T14:29:41.037074Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\persp\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8 0.4 0.5 0.6]\n",
      " [0.1 0.9 0.2 0.4]\n",
      " [0.1 0.9 0.4 0.2]]\n",
      "[1 1 2]\n",
      "[False  True  True]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "A = tf.Variable([[0.8, 0.4, 0.5, 0.6],[0.1, 0.9, 0.2, 0.4],[0.1, 0.9, 0.4, 0.2]])\n",
    "B = tf.Variable([1, 1, 2])\n",
    "result = tf.nn.in_top_k(A, B, 2)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(A))\n",
    "    print(sess.run(B))\n",
    "    print(sess.run(result))\n",
    "#   k=1 [False True False]\n",
    "#   k=2 [False True True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-07T14:12:33.927239Z",
     "start_time": "2019-03-07T14:12:33.918243Z"
    }
   },
   "source": [
    "placeholder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
